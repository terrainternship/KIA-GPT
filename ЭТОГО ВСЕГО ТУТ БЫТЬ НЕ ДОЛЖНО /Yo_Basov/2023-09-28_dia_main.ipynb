{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ЧЕРНОВОЙ ВАРИАНТ ПО НЕЙРО-КОПИРАЙТЕРУ ДИАЛОГОВ С ПРОМПТАМИ ИЗ СКРИПТОВ ОПЕРАТОРОВ В COLAB\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F7wICnhUDab",
        "outputId": "b4b7ee4e-2d75-4190-87ab-ff83bad0050c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/drive/MyDrive/KIA_DIALOG/Copywriter/KIA/BASE/\"\n",
        "!mkdir -p \"/content/drive/MyDrive/KIA_DIALOG/Copywriter/KIA/BASE/\""
      ],
      "metadata": {
        "id": "bvNZedIsUOme"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "KEY=\"ONLY_6\"\n",
        "ALL_FIRST_TEXTS={\n",
        " \"ONLY_6\": \"https://docs.google.com/spreadsheets/d/1VRk8vvIx-u4OjSKx15VNRVQhvw3qO1ug/export?format=xlsx\"\n",
        ", \"ONLY_7\": \"https://docs.google.com/spreadsheets/d/1zLaDn598Mm9zs0w1To55rcpAoeMjfuRH/export?format=xlsx\"\n",
        "}\n",
        "FIRST_TEXTS={KEY: ALL_FIRST_TEXTS[KEY]}\n",
        "\n",
        "ALL_FIRST_SHEETS={\n",
        "  \"ONLY_6\": \"Service Maintenance\"\n",
        ", \"ONLY_7\": \"Systems and Applications\"\n",
        "}\n",
        "FIRST_SHEETS={KEY: ALL_FIRST_SHEETS[KEY]}"
      ],
      "metadata": {
        "id": "4jUlakf1O6Yb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLWs9eLRC63S"
      },
      "source": [
        "# Установка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wu61Uz2K__i6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3b84a8-4587-4b2a-95d1-af531dcdd65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Введите секретный ключ для сервиса chatGPT: ··········\n"
          ]
        }
      ],
      "source": [
        "# @title Установка пакетов\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install --upgrade tiktoken\n",
        "!pip install langchain openai\n",
        "!pip install faiss-cpu\n",
        "!pip install urllib\n",
        "\n",
        "clear_output()\n",
        "\n",
        "import getpass\n",
        "import openai\n",
        "import os\n",
        "def get_key_ОpenAI():\n",
        "  openai.api_key = getpass.getpass(prompt='Введите секретный ключ для сервиса chatGPT: ')\n",
        "  os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
        "\n",
        "get_key_ОpenAI()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Установка библиотек\n",
        "!pip install tiktoken langchain openai chromadb gspread oauth2client nltk pydantic==1.10.8 faiss-cpu python-docx"
      ],
      "metadata": {
        "id": "zIBD7aFKkfML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf665648-ceaf-4ed4-a00d-82cba82ea71e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.301)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.13)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (4.1.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pydantic==1.10.8 in /usr/local/lib/python3.10/dist-packages (1.10.8)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (0.8.11)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.8) (4.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.40)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.103.1)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.23.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.0.2)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.14.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.0.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from gspread) (2.17.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.9.1->oauth2client) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: huggingface_hub<0.17,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.16.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (5.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CVo7kzfodp-0"
      },
      "outputs": [],
      "source": [
        "#@title Импорт библиотек и Сервисные функции\n",
        "import gdown\n",
        "from IPython.display import clear_output\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.docstore.document import Document\n",
        "import requests\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts import PromptTemplate\n",
        "import pathlib\n",
        "import subprocess\n",
        "import tempfile\n",
        "\n",
        "import time\n",
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "import getpass\n",
        "\n",
        "\n",
        "# ----------------------------------\n",
        "MODEL_TURBO_16K = \"gpt-3.5-turbo-16k\"\n",
        "MODEL_TURBO_0613 = \"gpt-3.5-turbo-0613\"\n",
        "MODEL_GPT4 = \"gpt-4-0613\"\n",
        "# ----------------------------------\n",
        "\n",
        "clear_output()\n",
        "\n",
        "class WorkerОpenAI():\n",
        "  def __init__(self, \\\n",
        "               system_promt = \" \", \\\n",
        "               system_promt_lector = \" \", \\\n",
        "               mod = MODEL_TURBO_16K, \\\n",
        "               content_topics = None, \\\n",
        "               save_project = '/content/'):\n",
        "    self.model = mod\n",
        "    self.save_project  = save_project\n",
        "\n",
        "    if content_topics:\n",
        "      self.content_topics = self.load_txt_file(content_topics)\n",
        "\n",
        "    # системные настройки\n",
        "    self.system_promt = self.load_document_text(system_promt)\n",
        "    self.speaker_system_promt = self.load_document_text(system_promt_lector)\n",
        "\n",
        "\n",
        "  def load_document_text(self, url: str) -> str:\n",
        "      # функция для загрузки документа по ссылке из гугл док\n",
        "      match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "      if match_ is None:\n",
        "          raise ValueError('Invalid Google Docs URL')\n",
        "      doc_id = match_.group(1)\n",
        "      response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "      response.raise_for_status()\n",
        "      text = response.text\n",
        "      return text\n",
        "\n",
        "\n",
        "  def load_txt_file(self, file_path):\n",
        "      with open(file_path, 'r') as file_:\n",
        "          text = file_.read()\n",
        "      return text\n",
        "\n",
        "  # пример подсчета токенов\n",
        "  def num_tokens_from_messages(self, messages):\n",
        "      \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
        "      try:\n",
        "          encoding = tiktoken.encoding_for_model(self.model)\n",
        "      except KeyError:\n",
        "          encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "      # if self.model == \"gpt-3.5-turbo-0301\":  # note: future models may deviate from this\n",
        "      if self.model in [\"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-16k\", \"gpt-4-0613\"]:  # note: future models may deviate from this\n",
        "          num_tokens = 0\n",
        "          for message in messages:\n",
        "              num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
        "              for key, value in message.items():\n",
        "                  num_tokens += len(encoding.encode(value))\n",
        "                  if key == \"name\":  # if there's a name, the role is omitted\n",
        "                      num_tokens += -1  # role is always required and always 1 token\n",
        "          num_tokens += 2  # every reply is primed with <im_start>assistant\n",
        "          return num_tokens\n",
        "      else:\n",
        "          raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {self.model}.\n",
        "  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")\n",
        "\n",
        "\n",
        "  def f00_create_embedding_faiss_db(self, doc_txt_dir=\"/content/\", \\\n",
        "                                faiss_db_dir =\"/content/\", \\\n",
        "                                start_idx = 0, \\\n",
        "                                collection_name = \" \"):\n",
        "\n",
        "    def f01_num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "      \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "      encoding = tiktoken.get_encoding(encoding_name)\n",
        "      num_tokens = len(encoding.encode(string))\n",
        "      return num_tokens\n",
        "\n",
        "    # Для Копирайтера\n",
        "    self.splitter = RecursiveCharacterTextSplitter(['\\n\\n', '\\n', ' '], chunk_size=1024, chunk_overlap=300)\n",
        "    idx_file_folder = start_idx-1\n",
        "    chunkID = idx_file_folder\n",
        "\n",
        "    count_tokens = 0\n",
        "    # проходимся по всем данным\n",
        "    for _, file_ in enumerate(sorted(os.listdir(doc_txt_dir))):\n",
        "        print(\"Загружается файл: \", file_)\n",
        "        self.file_name = file_\n",
        "        idx_file_folder +=1\n",
        "        source_chunks = []\n",
        "        # разбиваем на несколько частей с помощью метода split_text\n",
        "        with open(doc_txt_dir + file_, \"r\") as f:\n",
        "          for chunk in self.splitter.split_text(f.read()):\n",
        "              chunkID += 1\n",
        "              source_chunks.append(Document(page_content=chunk, \\\n",
        "                                  metadata={'source': file_,\n",
        "                                            'chunkID': chunkID,\n",
        "                                            \"collection_name\": collection_name,\n",
        "                                            'idx_file_folder': idx_file_folder}))\n",
        "\n",
        "\n",
        "        # Создание индексов документа и СОХРАНЕНИЕ\n",
        "        # Если документ не пуст, то создать и сохранить базу индексов эмбеддингов отрезков документа\n",
        "        if len(source_chunks) > 0:\n",
        "            self.db = FAISS.from_documents(source_chunks, OpenAIEmbeddings())\n",
        "            count_token = f01_num_tokens_from_string(' '.join([x.page_content for x in source_chunks]), \"cl100k_base\")\n",
        "            count_tokens += count_token\n",
        "            print('Количество токенов в документе :', count_token)\n",
        "            # print('ЦЕНА запроса:', 0.0004 * (count_token / 1000), ' $')\n",
        "\n",
        "            self.db.save_local(os.path.join(faiss_db_dir, collection_name, f\"{str(idx_file_folder)}_db_initial__{file_[:20]}\"))\n",
        "\n",
        "    print('\\nЦЕНА запроса создания базы индексов:', 0.0004 * (count_tokens / 1000), ' $')\n",
        "\n",
        "  # ЗАПРС в ChatGPT\n",
        "  def get_ChatCompletion(self, model,  # указываем модель\n",
        "                         messages,     # словарь запроса\n",
        "                         temp=0.1):    # температуру\n",
        "\n",
        "      completion = openai.ChatCompletion.create(\n",
        "        model= model,\n",
        "        messages= messages,\n",
        "        temperature= temp\n",
        "        )\n",
        "\n",
        "      print(f'{completion[\"usage\"][\"total_tokens\"]} токенов использовано всего (вопрос-ответ).')\n",
        "      # print('ЦЕНА запроса с ответом :', 0.0015*(completion[\"usage\"][\"total_tokens\"]/1000), ' $')\n",
        "      print('===========================================: \\n')\n",
        "      return completion.choices[0].message.content\n",
        "\n",
        "  # ЗАПРС на создание темы и подтемы по Материалам\n",
        "  def get_search_materials_topics_subtopics(self, materials, model_topics = \"gpt-3.5-turbo-16k\"):\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{self.system_promt}\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"Проанализируй отрывок материала из диалога с другими клиентами: {materials}.\n",
        "• дай компактный, сжатый, обобщенный список тем и подтем.\n",
        "• Темы Необходимо оформить #, а подтемы оформить ##_.\n",
        "• Используй только такой пример, ничего не добавляй лишнего.\n",
        "• Пример составления списка:\n",
        "Пример составления списка:\n",
        "_#...\n",
        "##_...\n",
        "_#...\n",
        "##_...\n",
        "        \"\"\"}\n",
        "        ]\n",
        "\n",
        "    # example token count from the function defined above\n",
        "    print(f\"{self.num_tokens_from_messages(messages=messages)} токенов использовано на вопрос \\n\")\n",
        "    try:\n",
        "      self.content_topics += self.get_ChatCompletion(model_topics, messages)\n",
        "    except:\n",
        "      print(\"Модель в настоящее время перегружена. Попробуйте позже.\")\n",
        "\n",
        "\n",
        "  # ПОИСК ТЕМЫ и ПОДТЕМЫ\n",
        "  def search_topics_subtopics(self, num_chunk = 10):\n",
        "    self.content_topics = ''\n",
        "    materials = \"\"\n",
        "    # Выбираем блоки ПОДРЯД\n",
        "    len_chunk = len(self.db.docstore._dict)\n",
        "    if len_chunk < num_chunk + 1:\n",
        "        for _, doc in self.db.docstore._dict.items():\n",
        "            materials += f\"{doc.page_content}\\n\"\n",
        "        self.get_search_materials_topics_subtopics(materials)\n",
        "    else:\n",
        "        for ind, (key, doc) in enumerate(self.db.docstore._dict.items()):\n",
        "          materials += f\"{doc.page_content}\\n\"\n",
        "          if (ind+1) % num_chunk == 0:\n",
        "            self.get_search_materials_topics_subtopics(materials)\n",
        "            materials = \"\"\n",
        "    if materials != \"\":\n",
        "        self.get_search_materials_topics_subtopics(materials)\n",
        "\n",
        "    print('Собрали список тем и подтем: ')\n",
        "    print(self.content_topics)\n",
        "\n",
        "    with open(f'{self.save_project}{self.file_name[:20]}__темы_подтемы.txt', \"w\") as f:\n",
        "      f.write(self.content_topics)\n",
        "\n",
        "\n",
        "  # ОБЪЕДИНЯЕМ схожие ТЕМЫ\n",
        "  def get_merge_topics(self, model_topics = \"gpt-3.5-turbo-16k\"):\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{self.system_promt}\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"Проанализируй Темы и подтемы из Текста диалогов специалиста с другими клиентами: {self.content_topics}.\n",
        "\n",
        "Необходимо объединить похожие по смыслу темы или подтемы, записать компактно.\n",
        "При необходимости перефразировать тему или подтему. Дай корректный список.\n",
        "Темы оформи _#, а подтемы оформи ##_.\n",
        "Используй только такой пример, ничего не добавляй лишнего.\n",
        "Пример составления списка:\n",
        "_#...\n",
        "##_...\n",
        "_#...\n",
        "##_...\n",
        "\"\"\"}\n",
        "]\n",
        "    # example token count from the function defined above\n",
        "    print(f\"{self.num_tokens_from_messages(messages=messages)} токенов использовано на вопрос \\n\")\n",
        "    try:\n",
        "      self.content_topics = self.get_ChatCompletion(model_topics, messages)\n",
        "      print('Итоговый список тем и подтем: ')\n",
        "      print(self.content_topics)\n",
        "      with open(f'{self.save_project}{self.file_name[:20]}__темы_подтемы_ИТОГ.txt', \"w\") as f:\n",
        "        f.write(self.content_topics)\n",
        "    except:\n",
        "      print(\"Модель в настоящее время перегружена. Попробуйте позже.\")\n",
        "\n",
        "  # ОРГАНИЗУЕМ текст блоками\n",
        "  def organize_text(self, topic, num_chunks, model_topics):\n",
        "\n",
        "    # Выборка документов по схожести с подтемой\n",
        "    docs = self.db.similarity_search(topic, k = num_chunks)\n",
        "    message_content = '\\n'.join([doc.page_content + '\\n' for i, doc in enumerate(docs)])\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"{self.speaker_system_promt}\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"Вот отрывки Вашей лекции:\\n{message_content}\n",
        "\n",
        "Опираясь только на информацию с Лекции, указанной выше, расскажите подробнее по Теме: {topic}.\n",
        "\"\"\"}\n",
        "      ]\n",
        "\n",
        "    # example token count from the function defined above\n",
        "    print('\\n ===========================================: ')\n",
        "    print(f\"{self.num_tokens_from_messages(messages=messages)} токенов использовано на вопрос \\n\")\n",
        "    try:\n",
        "      self.final_text += self.get_ChatCompletion(model_topics, messages)\n",
        "    except:\n",
        "      print(\"Модель в настоящее время перегружена. Попробуйте позже.\")\n",
        "\n",
        "  # ОРГАНИЗУЕМ ИТОГОВЫЙ ТЕКСТ\n",
        "  def organize_final_text(self, num_chunks = 10,\n",
        "                          model_topics = \"gpt-3.5-turbo-16k\",\n",
        "                          name = None,\n",
        "                          db_path = None):\n",
        "    if name:\n",
        "      self.file_name = name\n",
        "\n",
        "    if db_path:\n",
        "      for curr_base in os.listdir(db_path):\n",
        "          self.db = FAISS.load_local(os.path.join(db_path, curr_base), OpenAIEmbeddings())\n",
        "\n",
        "    self.final_text = \"\"\n",
        "    list_topics = self.content_topics.split('\\n')\n",
        "    # проходимся по списку тем и подтем\n",
        "    for ind, topic in tqdm(enumerate(list_topics)):\n",
        "        # тему просто записываем в итоговый текст\n",
        "        if (\"_#\" in topic) and not(\"_#\" in list_topics[ind+1]):\n",
        "          self.final_text += f'\\n{topic}\\n'\n",
        "        # подтему передаем в ChatGPT\n",
        "        else:\n",
        "          self.final_text += f'\\n{topic}\\n'\n",
        "          self.organize_text(topic, num_chunks, model_topics)\n",
        "\n",
        "    with open(f'{self.save_project}{self.file_name[:20]}__final_text.txt', \"w\") as f:\n",
        "      f.write(self.final_text)\n",
        "    print(\"\\nСоздали финальный документ для Базы Знаний (final_text)\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEB6lfh3vRYc"
      },
      "source": [
        "# Copywriter. Нейро-Копийтер для MarkdownHeaderTextSplitter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создаем текстовый файл с диалогами из Гугл таблицы"
      ],
      "metadata": {
        "id": "6BAWGeYk07T5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openpyxl import Workbook, load_workbook\n",
        "from io import BytesIO\n",
        "import urllib\n",
        "\n",
        "# Шаг 1: Загрузить xlsx файл из Google Drive\n",
        "google_sheet_url = FIRST_TEXTS[KEY]\n",
        "file = urllib.request.urlopen(google_sheet_url).read()\n",
        "\n",
        "wb=load_workbook(filename=BytesIO(file))\n",
        "sheet_ranges=wb[FIRST_SHEETS[KEY]]\n",
        "\n",
        "# Шаг 2: Извлечь столбец \"text\"\n",
        "text_column = \"\"\n",
        "for row in sheet_ranges.iter_rows():\n",
        "    first = False\n",
        "    last = False\n",
        "    for cell in row:\n",
        "        if not first and not last:\n",
        "            text_column += str(cell.value) + \"\\n\"\n",
        "            last = True\n",
        "        first = True\n",
        "\n",
        "# Шаг 3: Заменить \"operatorMessage: Здравствуйте\" на \"<operatorMessage: Здравствуйте>\"\n",
        "text_column = text_column.replace(\"operatorMessage: Здравствуйте\", \"<operatorMessage: Здравствуйте>\")\n",
        "\n",
        "# Шаг 4: Сохранить в файл \"dialog.txt\" в корне Colab\n",
        "with open(\"/content/drive/MyDrive/KIA_DIALOG/Copywriter/KIA/BASE/kia_dialog_\" + KEY + \".txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(str(text_column) + \"\\n\")\n",
        "\n",
        "print(\"Файл kia_dialog_\" + KEY + \".txt успешно сохранен!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAiIIDsbbjc6",
        "outputId": "f9594292-b897-4b3a-c1e3-c2c0549ba33e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл kia_dialog_ONLY_6.txt успешно сохранен!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KYNb1d6q4hWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f0b309-5c21-4c5b-a365-111663842c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загружается файл:  kia_dialog_ONLY_6.txt\n",
            "Количество токенов в документе : 916\n",
            "\n",
            "ЦЕНА запроса создания базы индексов: 0.0003664  $\n"
          ]
        }
      ],
      "source": [
        "#@title Создаем объект для работы Copywriter\n",
        "projects_dir = '/content/drive/MyDrive/KIA_DIALOG/Copywriter/KIA/'\n",
        "\n",
        "Promt_copywriter = \"https://docs.google.com/document/d/15bNgGsY2MPrgfnUasyHX0SslylqLGAm7/edit?usp=sharing\"\n",
        "Promt_lector = \"https://docs.google.com/document/d/1N0PUuhI8zP8Iu_4kZIuF5pIht78hQvg2/edit?usp=sharing\"\n",
        "\n",
        "# если темы созданы\n",
        "# topics_final = \"/content/drive/MyDrive/Colab Notebooks/_Projects_ChatGPT/Нейро_Copywriter/УИИ/___.txt\"\n",
        "# # Создаем объект для дообучения chatGPT\n",
        "curator = WorkerОpenAI(system_promt = Promt_copywriter, # системный промт\n",
        "                       system_promt_lector = Promt_lector, # промт Лектора\n",
        "                      #  content_topics = topics_final,\n",
        "                       save_project = projects_dir)     # путь для сохранения готовых файлов\n",
        "\n",
        "# Формируем базу по файлу txt\n",
        "# путь к материалам\n",
        "doc_txt_dir = projects_dir + 'BASE/'\n",
        "db_initial = projects_dir\n",
        "\n",
        "curator.f00_create_embedding_faiss_db(doc_txt_dir = doc_txt_dir,   # путь к материалам\n",
        "                                faiss_db_dir = db_initial,     # путь для сохранения исходной базы\n",
        "                                start_idx = 0,                 # номер документа в базе\n",
        "                                collection_name = 'KIA_db_initial')  # наименование коллекции\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# curator.create_embedding_faiss_db(doc_txt_dir = doc_txt_dir,   # путь к материалам\n",
        "#                                 faiss_db_dir = db_initial,     # путь для сохранения исходной базы\n",
        "#                                 start_idx = 0,                 # номер документа в базе\n",
        "#                                 collection_name = 'УИИ_db_initial')  # наименование коллекции\n",
        "\n",
        "\n",
        "# curator.create_embedding_one_file(doc_txt_dir = doc_txt_dir,   # путь к материалам\n",
        "#                                   file_ = file_name,            # какой файл берем\n",
        "#                                   faiss_db_dir = projects_dir)     # путь для сохранения исходной базы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "qztY_BvINnUB",
        "outputId": "5cd46281-dc22-4032-bf9d-f0f183fa56f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2434508b167c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m curator.create_embedding_faiss_db(doc_txt_dir = doc_txt_dir,   # путь к материалам\n\u001b[0m\u001b[1;32m      2\u001b[0m                                 \u001b[0mfaiss_db_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_initial\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0;31m# путь для сохранения исходной базы\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0;31m# номер документа в базе\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 collection_name = 'УИИ_db_initial')  # наименование коллекции\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'WorkerОpenAI' object has no attribute 'create_embedding_faiss_db'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sGRXeHMLCfpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa43b00-3111-4ac8-c7f0-37c237959be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст разбит на чанки. Всего: 2 шт.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([Document(page_content='3.0\\n7.0\\n10.0\\n11.0\\n12.0\\n17.0\\n28.0\\n29.0\\n34.0\\n35.0\\n39.0\\n41.0\\n48.0\\n51.0\\n55.0\\n62.0\\n63.0\\n67.0\\n71.0\\n77.0\\n78.0\\n81.0\\n82.0\\n90.0\\n91.0\\n96.0\\n98.0\\n99.0\\n100.0\\n106.0\\n110.0\\n111.0\\n112.0\\n113.0\\n124.0\\n126.0\\n134.0\\n143.0\\n149.0\\n151.0\\n153.0\\n154.0\\n158.0\\n165.0\\n168.0\\n174.0\\n177.0\\n179.0\\n180.0\\n182.0\\n196.0\\n198.0\\n199.0\\n201.0\\n203.0\\n213.0\\n214.0\\n221.0\\n222.0\\n223.0\\n229.0\\n234.0\\n235.0\\n240.0\\n241.0\\n242.0\\n245.0\\n249.0\\n252.0\\n255.0\\n258.0\\n262.0\\n266.0\\n272.0\\n278.0\\n282.0\\n284.0\\n285.0\\n287.0\\n292.0\\n297.0\\n304.0\\n305.0\\n313.0\\n315.0\\n318.0\\n321.0\\n322.0\\n326.0\\n327.0\\n331.0\\n335.0\\n337.0\\n341.0\\n347.0\\n349.0\\n359.0\\n360.0\\n362.0\\n363.0\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone', metadata={'source': 'kia_dialog_ONLY_6.txt', 'chunkID': 0, 'collection_name': 'KIA_db_initial', 'idx_file_folder': 0}), Document(page_content='None\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone\\nNone', metadata={'source': 'kia_dialog_ONLY_6.txt', 'chunkID': 1, 'collection_name': 'KIA_db_initial', 'idx_file_folder': 0})])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Смотрим созданные чанки\n",
        "print(f\"Текст разбит на чанки. Всего: {len(curator.db.docstore._dict.values())} шт.\\n\")\n",
        "curator.db.docstore._dict.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3TLVJMHbJXPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24b0048-d7c2-49be-ff46-72c8c98af7dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1195 токенов использовано на вопрос \n",
            "\n",
            "1830 токенов использовано всего (вопрос-ответ).\n",
            "===========================================: \n",
            "\n",
            "1195 токенов использовано на вопрос \n",
            "\n",
            "1830 токенов использовано всего (вопрос-ответ).\n",
            "===========================================: \n",
            "\n",
            "Собрали список тем и подтем: \n",
            "# Темы:\n",
            "\n",
            "1. Отрывок материала из диалога с другими клиентами\n",
            "\n",
            "## Подтемы:\n",
            "\n",
            "- 3.0\n",
            "- 7.0\n",
            "- 10.0\n",
            "- 11.0\n",
            "- 12.0\n",
            "- 17.0\n",
            "- 28.0\n",
            "- 29.0\n",
            "- 34.0\n",
            "- 35.0\n",
            "- 39.0\n",
            "- 41.0\n",
            "- 48.0\n",
            "- 51.0\n",
            "- 55.0\n",
            "- 62.0\n",
            "- 63.0\n",
            "- 67.0\n",
            "- 71.0\n",
            "- 77.0\n",
            "- 78.0\n",
            "- 81.0\n",
            "- 82.0\n",
            "- 90.0\n",
            "- 91.0\n",
            "- 96.0\n",
            "- 98.0\n",
            "- 99.0\n",
            "- 100.0\n",
            "- 106.0\n",
            "- 110.0\n",
            "- 111.0\n",
            "- 112.0\n",
            "- 113.0\n",
            "- 124.0\n",
            "- 126.0\n",
            "- 134.0\n",
            "- 143.0\n",
            "- 149.0\n",
            "- 151.0\n",
            "- 153.0\n",
            "- 154.0\n",
            "- 158.0\n",
            "- 165.0\n",
            "- 168.0\n",
            "- 174.0\n",
            "- 177.0\n",
            "- 179.0\n",
            "- 180.0\n",
            "- 182.0\n",
            "- 196.0\n",
            "- 198.0\n",
            "- 199.0\n",
            "- 201.0\n",
            "- 203.0\n",
            "- 213.0\n",
            "- 214.0\n",
            "- 221.0\n",
            "- 222.0\n",
            "- 223.0\n",
            "- 229.0\n",
            "- 234.0\n",
            "- 235.0\n",
            "- 240.0\n",
            "- 241.0\n",
            "- 242.0\n",
            "- 245.0\n",
            "- 249.0\n",
            "- 252.0\n",
            "- 255.0\n",
            "- 258.0\n",
            "- 262.0\n",
            "- 266.0\n",
            "- 272.0\n",
            "- 278.0\n",
            "- 282.0\n",
            "- 284.0\n",
            "- 285.0\n",
            "- 287.0\n",
            "- 292.0\n",
            "- 297.0\n",
            "- 304.0\n",
            "- 305.0\n",
            "- 313.0\n",
            "- 315.0\n",
            "- 318.0\n",
            "- 321.0\n",
            "- 322.0\n",
            "- 326.0\n",
            "- 327.0\n",
            "- 331.0\n",
            "- 335.0\n",
            "- 337.0\n",
            "- 341.0\n",
            "- 347.0\n",
            "- 349.0\n",
            "- 359.0\n",
            "- 360.0\n",
            "- 362.0\n",
            "- 363.0# Темы:\n",
            "\n",
            "1. Отрывок материала из диалога с другими клиентами\n",
            "\n",
            "## Подтемы:\n",
            "\n",
            "- 3.0\n",
            "- 7.0\n",
            "- 10.0\n",
            "- 11.0\n",
            "- 12.0\n",
            "- 17.0\n",
            "- 28.0\n",
            "- 29.0\n",
            "- 34.0\n",
            "- 35.0\n",
            "- 39.0\n",
            "- 41.0\n",
            "- 48.0\n",
            "- 51.0\n",
            "- 55.0\n",
            "- 62.0\n",
            "- 63.0\n",
            "- 67.0\n",
            "- 71.0\n",
            "- 77.0\n",
            "- 78.0\n",
            "- 81.0\n",
            "- 82.0\n",
            "- 90.0\n",
            "- 91.0\n",
            "- 96.0\n",
            "- 98.0\n",
            "- 99.0\n",
            "- 100.0\n",
            "- 106.0\n",
            "- 110.0\n",
            "- 111.0\n",
            "- 112.0\n",
            "- 113.0\n",
            "- 124.0\n",
            "- 126.0\n",
            "- 134.0\n",
            "- 143.0\n",
            "- 149.0\n",
            "- 151.0\n",
            "- 153.0\n",
            "- 154.0\n",
            "- 158.0\n",
            "- 165.0\n",
            "- 168.0\n",
            "- 174.0\n",
            "- 177.0\n",
            "- 179.0\n",
            "- 180.0\n",
            "- 182.0\n",
            "- 196.0\n",
            "- 198.0\n",
            "- 199.0\n",
            "- 201.0\n",
            "- 203.0\n",
            "- 213.0\n",
            "- 214.0\n",
            "- 221.0\n",
            "- 222.0\n",
            "- 223.0\n",
            "- 229.0\n",
            "- 234.0\n",
            "- 235.0\n",
            "- 240.0\n",
            "- 241.0\n",
            "- 242.0\n",
            "- 245.0\n",
            "- 249.0\n",
            "- 252.0\n",
            "- 255.0\n",
            "- 258.0\n",
            "- 262.0\n",
            "- 266.0\n",
            "- 272.0\n",
            "- 278.0\n",
            "- 282.0\n",
            "- 284.0\n",
            "- 285.0\n",
            "- 287.0\n",
            "- 292.0\n",
            "- 297.0\n",
            "- 304.0\n",
            "- 305.0\n",
            "- 313.0\n",
            "- 315.0\n",
            "- 318.0\n",
            "- 321.0\n",
            "- 322.0\n",
            "- 326.0\n",
            "- 327.0\n",
            "- 331.0\n",
            "- 335.0\n",
            "- 337.0\n",
            "- 341.0\n",
            "- 347.0\n",
            "- 349.0\n",
            "- 359.0\n",
            "- 360.0\n",
            "- 362.0\n",
            "- 363.0\n"
          ]
        }
      ],
      "source": [
        "#@title Поиск темы и подтемы выборкой по 5 - 15 чанков\n",
        "\n",
        "# Подаем в цикле и просим составить список тем и подтем.\n",
        "curator.search_topics_subtopics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xbrAFSweUxC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21244a46-74d1-425e-f6ca-dc3e9012a139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1579 токенов использовано на вопрос \n",
            "\n",
            "2115 токенов использовано всего (вопрос-ответ).\n",
            "===========================================: \n",
            "\n",
            "Итоговый список тем и подтем: \n",
            "# Темы:\n",
            "\n",
            "1. Отрывок материала из диалога с другими клиентами\n",
            "\n",
            "## Подтемы:\n",
            "\n",
            "- 3.0, 7.0, 10.0, 11.0, 12.0, 17.0, 28.0, 29.0, 34.0, 35.0, 39.0, 41.0, 48.0, 51.0, 55.0, 62.0, 63.0, 67.0, 71.0, 77.0, 78.0, 81.0, 82.0, 90.0, 91.0, 96.0, 98.0, 99.0, 100.0, 106.0, 110.0, 111.0, 112.0, 113.0, 124.0, 126.0, 134.0, 143.0, 149.0, 151.0, 153.0, 154.0, 158.0, 165.0, 168.0, 174.0, 177.0, 179.0, 180.0, 182.0, 196.0, 198.0, 199.0, 201.0, 203.0, 213.0, 214.0, 221.0, 222.0, 223.0, 229.0, 234.0, 235.0, 240.0, 241.0, 242.0, 245.0, 249.0, 252.0, 255.0, 258.0, 262.0, 266.0, 272.0, 278.0, 282.0, 284.0, 285.0, 287.0, 292.0, 297.0, 304.0, 305.0, 313.0, 315.0, 318.0, 321.0, 322.0, 326.0, 327.0, 331.0, 335.0, 337.0, 341.0, 347.0, 349.0, 359.0, 360.0, 362.0, 363.0\n"
          ]
        }
      ],
      "source": [
        "#@title Корректируем список тем и подтем (обобщаем, убираем дубли).\n",
        "# Подаем сформированный Список тем и просим объединить похожие по смыслу темы или подтемы, записать компактно.\n",
        "# При необходимости перефразировать тему или подтему.\n",
        "curator.get_merge_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ОРГАНИЗУЕМ ИТОГОВЫЙ ТЕКСТ"
      ],
      "metadata": {
        "id": "qIm6znHAtWVL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выборка блоков документов по схожести с подтемой. Передаем собранные отрывки с Лекции и просим рассказать подробнее, опираясь на Лекцию."
      ],
      "metadata": {
        "id": "2fWybucTLHnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# запускаем сбору Итогового Текста\n",
        "# name_file = 'Разбор нейро-сотрудников на chatGPT _ 21.08.2023'\n",
        "# db_initial = '/content/drive/MyDrive/Colab Notebooks/_Projects_ChatGPT/Нейро_Copywriter/УИИ/УИИ_db_initial'\n",
        "\n",
        "# curator.organize_final_text(name = name_file, db_path = db_initial)\n",
        "curator.organize_final_text()"
      ],
      "metadata": {
        "id": "tzRnco4xRX19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871,
          "referenced_widgets": [
            "837a1a92b15e445da85569caa90d2cb6",
            "d054a2532dec4a83ac8d7601b5d1cf99",
            "01a7a88a6e5f4a10bda611866ff3b558",
            "e77ef6373e26422e90866fa920a0ddcf",
            "3331235729594714822d083eadb8da1f",
            "a583a68aca334051aa4ae0e8e752b37c",
            "225bf3a5de5c4660a4fd0e8cf93107ac",
            "38dd0ac10d154d6c832c8e7c990610a4",
            "c02acbc985f94d7b9a50e0ea50e7f86a",
            "3ae9377a89474681b8f84800ff404813",
            "ede4a59de56f4d85b71666ca809b882e"
          ]
        },
        "outputId": "a578fb14-07e9-4ac0-8771-cfa3655fefd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "837a1a92b15e445da85569caa90d2cb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===========================================: \n",
            "1155 токенов использовано на вопрос \n",
            "\n",
            "2433 токенов использовано всего (вопрос-ответ).\n",
            "===========================================: \n",
            "\n",
            "\n",
            " ===========================================: \n",
            "1150 токенов использовано на вопрос \n",
            "\n",
            "2379 токенов использовано всего (вопрос-ответ).\n",
            "===========================================: \n",
            "\n",
            "\n",
            " ===========================================: \n",
            "1175 токенов использовано на вопрос \n",
            "\n",
            "2494 токенов использовано всего (вопрос-ответ).\n",
            "===========================================: \n",
            "\n",
            "\n",
            " ===========================================: \n",
            "1150 токенов использовано на вопрос \n",
            "\n",
            "2284 токенов использовано всего (вопрос-ответ).\n",
            "===========================================: \n",
            "\n",
            "\n",
            " ===========================================: \n",
            "1157 токенов использовано на вопрос \n",
            "\n",
            "2146 токенов использовано всего (вопрос-ответ).\n",
            "===========================================: \n",
            "\n",
            "\n",
            " ===========================================: \n",
            "1150 токенов использовано на вопрос \n",
            "\n",
            "2339 токенов использовано всего (вопрос-ответ).\n",
            "===========================================: \n",
            "\n",
            "\n",
            " ===========================================: \n",
            "1650 токенов использовано на вопрос \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сформирован итоговый текст\n",
        "curator.final_text"
      ],
      "metadata": {
        "id": "iETHjZJRTnFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MarkdownHeaderTextSplitter"
      ],
      "metadata": {
        "id": "uB6aUKeui5Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title функции\n",
        "chat_manager_system = \"\"\"\n",
        "Ты Специалист, готовящий текст для обучающего материала. Ты профессионал своего дела.\n",
        "Тебе предоставят отрывок Твоего Текста и попросят раскрыть подробнее одну из тем обучающего материала.\n",
        "Твоя цель: Опираясь только на Текст, подробно, развернуто рассказать по интересующей теме на русском языке.\n",
        "Необходимо уложиться в 2000 токенов.\n",
        "\"\"\"\n",
        "\n",
        "def get_chatgpt_answer(topic,  db, model = MODEL_TURBO_0613):\n",
        "  # Выборка документов по схожести с вопросом\n",
        "  docs = db.similarity_search(topic, k=4)\n",
        "  message_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\n  ' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n",
        "  # print('message_content :\\n ======================================== \\n', self.message_content)\n",
        "\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": f\"{chat_manager_system}\"},\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"Analyze step by step and give a detailed correct answer to the Student's question.\\n\n",
        "    Question:\\n{topic}\\n\\nMaterials from the Webinar:\\n{message_content}\\n\\nAnswer:\"\"\"}\n",
        "    ]\n",
        "\n",
        "  try:\n",
        "    completion = openai.ChatCompletion.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    temperature=0.1\n",
        "    )\n",
        "\n",
        "    print(f'{completion[\"usage\"][\"total_tokens\"]} токенов использовано всего (вопрос-ответ).')\n",
        "    print('ЦЕНА запроса с ответом :', 0.0015*(completion[\"usage\"][\"total_tokens\"]/1000), ' $')\n",
        "    print('===========================================: \\n')\n",
        "    print('Ответ ChatGPT: ')\n",
        "    print(completion.choices[0].message.content)\n",
        "    # return completion.choices[0].message.content\n",
        "  except:\n",
        "    print(\"Модель в настоящее время перегружена. Попробуйте позже.\")\n",
        "\n",
        "def load_txt_file(file_path):\n",
        "    with open(file_path, 'r') as file_:\n",
        "        text = file_.read()\n",
        "    return text\n",
        "\n",
        "projects_dir = '/content/drive/MyDrive/KIA_DIALOG/Copywriter/KIA/'\n",
        "name_file = \"kia_dialog_\" + KEY + '.tx__final_text.txt' # FIXME\n",
        "final_text_dir = projects_dir + name_file\n",
        "\n",
        "# Загружаем итоговый текст\n",
        "final_text = load_txt_file(final_text_dir)\n"
      ],
      "metadata": {
        "id": "IN3nV98Ti14W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Готовим документ MarkdownHeader по сформированному тексту\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "\n",
        "headers_to_split_on = [\n",
        "    (\"_#\", \"Header 1\"),\n",
        "    (\"##_\", \"Header 2\"),\n",
        "    (\"###_\", \"Header 3\"),\n",
        "    (\"####_\", \"Header 4\"),\n",
        "    (\"#####_\", \"Header 5\"),\n",
        "]\n",
        "\n",
        "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "md_header_splits = markdown_splitter.split_text(final_text)\n",
        "md_header_splits"
      ],
      "metadata": {
        "id": "yno60mdeR9lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1024, chunk_overlap=300\n",
        ")\n",
        "\n",
        "# Split\n",
        "split = text_splitter.split_documents(md_header_splits)\n",
        "db = FAISS.from_documents(split, OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "I4IBWVoNu63m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split[1]"
      ],
      "metadata": {
        "id": "_yu7ynmx63e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic1 = \"\"\"\n",
        "Почем сегодня тормозные колодки?\n",
        "\"\"\"\n",
        "\n",
        "get_chatgpt_answer(topic1,  db)"
      ],
      "metadata": {
        "id": "nxRm8e134sjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic2 = \"\"\"\n",
        "Почему сайт kia.ru не работает?\n",
        "\"\"\"\n",
        "\n",
        "get_chatgpt_answer(topic2,  db)"
      ],
      "metadata": {
        "id": "QFGtb7-5tc6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic3 = \"\"\"\n",
        "Какую длину и ширину имеет тормозная колодка?\n",
        "\"\"\"\n",
        "\n",
        "get_chatgpt_answer(topic3,  db)"
      ],
      "metadata": {
        "id": "SvHg-dkxtiTK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "837a1a92b15e445da85569caa90d2cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d054a2532dec4a83ac8d7601b5d1cf99",
              "IPY_MODEL_01a7a88a6e5f4a10bda611866ff3b558",
              "IPY_MODEL_e77ef6373e26422e90866fa920a0ddcf"
            ],
            "layout": "IPY_MODEL_3331235729594714822d083eadb8da1f"
          }
        },
        "d054a2532dec4a83ac8d7601b5d1cf99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a583a68aca334051aa4ae0e8e752b37c",
            "placeholder": "​",
            "style": "IPY_MODEL_225bf3a5de5c4660a4fd0e8cf93107ac",
            "value": ""
          }
        },
        "01a7a88a6e5f4a10bda611866ff3b558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38dd0ac10d154d6c832c8e7c990610a4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c02acbc985f94d7b9a50e0ea50e7f86a",
            "value": 1
          }
        },
        "e77ef6373e26422e90866fa920a0ddcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae9377a89474681b8f84800ff404813",
            "placeholder": "​",
            "style": "IPY_MODEL_ede4a59de56f4d85b71666ca809b882e",
            "value": " 6/? [02:04&lt;00:00, 19.64s/it]"
          }
        },
        "3331235729594714822d083eadb8da1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a583a68aca334051aa4ae0e8e752b37c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225bf3a5de5c4660a4fd0e8cf93107ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38dd0ac10d154d6c832c8e7c990610a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c02acbc985f94d7b9a50e0ea50e7f86a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ae9377a89474681b8f84800ff404813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ede4a59de56f4d85b71666ca809b882e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}