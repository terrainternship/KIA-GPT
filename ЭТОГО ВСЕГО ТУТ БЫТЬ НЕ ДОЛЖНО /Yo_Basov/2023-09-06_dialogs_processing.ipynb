{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Обработка диалогов Киа"
      ],
      "metadata": {
        "id": "-0Za100dCIlV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpU5WNX6nYyD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Шаг 1: Загрузить xlsx файл из Google Drive\n",
        "google_sheet_url = \"https://docs.google.com/spreadsheets/d/1OKS6LZNq9AZo_WkGw9y6jb_o7VTGUbl_rX329vLQEz0/export?format=xlsx\"\n",
        "response = requests.get(google_sheet_url)\n",
        "data = pd.read_excel(BytesIO(response.content))\n",
        "\n",
        "# Шаг 2: Извлечь столбец \"text\"\n",
        "text_column = data[\"text\"]\n",
        "\n",
        "# Шаг 3: Заменить \"operatorMessage: Здравствуйте\" на \"<operatorMessage: Здравствуйте>\"\n",
        "text_column = text_column.str.replace(\"operatorMessage: Здравствуйте\", \"<operatorMessage: Здравствуйте>\")\n",
        "\n",
        "# Шаг 4: Сохранить в файл \"dialog.txt\" в корне Colab\n",
        "with open(\"/content/kia_dialog.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for text in text_column:\n",
        "        f.write(str(text) + \"\\n\")\n",
        "\n",
        "print(\"Файл kia_dialog.txt успешно сохранен!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai tiktoken langchain faiss-cpu"
      ],
      "metadata": {
        "id": "h6Yom98ADJ3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import getpass\n",
        "import openai\n",
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "# Получение ключа API от пользователя и установка его как переменной окружения\n",
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key"
      ],
      "metadata": {
        "id": "8weElY4DDQCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Первый вариант подсчета токенов:"
      ],
      "metadata": {
        "id": "Nx2-_37ZOWma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
        "    \"\"\"Возвращает количество токенов, используемых списком сообщений.\"\"\"\n",
        "    try:\n",
        "        encoding = tiktoken.encoding_for_model(model) # Пытаемся получить кодировку для выбранной модели\n",
        "    except KeyError:\n",
        "        encoding = tiktoken.get_encoding(\"cl100k_base\") # если не получается, используем кодировку \"cl100k_base\"\n",
        "    if model == \"gpt-3.5-turbo-0301\" or \"gpt-3.5-turbo-0613\" or \"gpt-3.5-turbo-16k\" or \"gpt-3.5-turbo\":\n",
        "        num_tokens = 0 # начальное значение счетчика токенов\n",
        "        for message in messages: # Проходимся по каждому сообщению в списке сообщений\n",
        "            num_tokens += 4  # каждое сообщение следует за <im_start>{role/name}\\n{content}<im_end>\\n, что равно 4 токенам\n",
        "            for key, value in message.items(): # итерация по элементам сообщения (роль, имя, контент)\n",
        "                num_tokens += len(encoding.encode(value)) # подсчет токенов в каждом элементе\n",
        "                if key == \"name\":  # если присутствует имя, роль опускается\n",
        "                    num_tokens += -1  # роль всегда требуется и всегда занимает 1 токен, так что мы вычитаем его, если имя присутствует\n",
        "        num_tokens += 2  # каждый ответ начинается с <im_start>assistant, что добавляет еще 2 токена\n",
        "        return num_tokens # возвращаем общее количество токенов\n",
        "    else:\n",
        "      # Если выбранная модель не поддерживается, генерируем исключение\n",
        "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}. # вызываем ошибку, если функция не реализована для конкретной модели\"\"\")"
      ],
      "metadata": {
        "id": "WyC86UJhEEfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system = ''' '''\n",
        "\n",
        "base_info= '''Основной контекст'''\n",
        "\n",
        "question = \"Суть вопроса\""
      ],
      "metadata": {
        "id": "5-OR0B4lE70H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "      {\"role\": \"system\", \"content\": system},\n",
        "      {\"role\": \"user\", \"content\": base_info+ f\"{question}\" }\n",
        "      ]\n"
      ],
      "metadata": {
        "id": "2QNeKfEVEo71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{num_tokens_from_messages(messages, 'gpt-3.5-turbo-0301')} токенов использовано на вопрос\")"
      ],
      "metadata": {
        "id": "XkyFEVIREGc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Второй вариант подсчета токенов:"
      ],
      "metadata": {
        "id": "gn504McTOgVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=system),\n",
        "    HumanMessage(content=base_info+ f\"{question}\")\n",
        "    ]"
      ],
      "metadata": {
        "id": "3l7xMNBlHW9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(temperature=0)\n",
        "chat.get_num_tokens_from_messages(messages)"
      ],
      "metadata": {
        "id": "TnWRzJIpHjkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим текст из файла kia_dialog.txt и разделим на отрезки(chunks)"
      ],
      "metadata": {
        "id": "QDbdwcECHymn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(\"/content/kia_dialog.txt\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "PxWpGFlkH0cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(separator=\"<\", chunk_size=10000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "EwjirkH6QwUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0])"
      ],
      "metadata": {
        "id": "g7XfFG0XM0g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "id": "sffEPFsLMpwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(documents)"
      ],
      "metadata": {
        "id": "o117_q2oKqY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(docs)"
      ],
      "metadata": {
        "id": "l_ZR86kWSP3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=system),\n",
        "    HumanMessage(content=f\"{docs[0]}\")\n",
        "    ]"
      ],
      "metadata": {
        "id": "h_1kGf8yIMW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat.get_num_tokens_from_messages(messages)"
      ],
      "metadata": {
        "id": "DtIkznbhIJis"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}